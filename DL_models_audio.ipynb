{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_models_audio.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rafi-ur-Rashid/Audio-News-Classification/blob/main/DL_models_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCLnCnCOyDeu"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFIljJ0PeG1v"
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from os import path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED=2245\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_SEED)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZd72-L7PwD2"
      },
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BtpnwzABUBK"
      },
      "source": [
        "corpus_path=r\"C:\\\\ML\\\\audio_news\\\\corpus\\\\\"\n",
        "preprocess_path=r\"C:\\\\ML\\\\audio_news\\\\preprocessed-shuffled\\\\\"\n",
        "mfcc_path=preprocess_path+r\"mfccs\\\\\"\n",
        "lables_path=preprocess_path+r\"lables\\\\\"\n",
        "mel_path=preprocess_path+r\"mel_specs\\\\\"\n",
        "weights_dir=\"C:\\\\ML\\\\audio_news\\\\weights\\\\\"\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzdFY1X4zdQH"
      },
      "source": [
        "#drive\n",
        "mfcc_path=\"/content/drive/My Drive/Colab Notebooks/Audio classification/mfccs/\"              \n",
        "lables_path=\"/content/drive/My Drive/Colab Notebooks/Audio classification/lables/\"  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpxtuCvYYXQ3"
      },
      "source": [
        "X_train=pickle.load( open(mfcc_path+\"train_13_2048_512.pkl\",'rb'))\n",
        "y_train=pickle.load( open(lables_path+\"train.pkl\",'rb'))\n",
        "X_test=pickle.load( open(mfcc_path+\"test_13_2048_512.pkl\",'rb'))\n",
        "y_test=pickle.load( open(lables_path+\"test.pkl\",'rb'))\n",
        "X_validation=pickle.load( open(mfcc_path+\"val_13_2048_512.pkl\",'rb'))\n",
        "y_validation=pickle.load( open(lables_path+\"val.pkl\",'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EQqrbgRr9sH5"
      },
      "source": [
        "#2d CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzsxGGn3Zc3I"
      },
      "source": [
        "X_train = X_train[..., np.newaxis]\n",
        "X_validation = X_validation[..., np.newaxis]\n",
        "X_test = X_test[..., np.newaxis]\n",
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2], 1)\n",
        "\n",
        "model = keras.Sequential()\n",
        "# 1st conv layer\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
        "model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 2nd conv layer\n",
        "model.add(keras.layers.Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((3, 3), strides=(2, 2), padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# 3rd conv layer\n",
        "model.add(keras.layers.Conv2D(32, (2, 2), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D((2, 2), strides=(2, 2), padding='same'))\n",
        "model.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# flatten output and feed it into dense layer\n",
        "model.add(keras.layers.Flatten())\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "saved_model=\"2DCNN_mfcc_13_2048_512.weights.hdf5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM9xhxpL3cdC"
      },
      "source": [
        "# LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bvVfFHF3YOc"
      },
      "source": [
        "\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "\n",
        "# build network topology\n",
        "model = keras.Sequential()\n",
        "\n",
        "# 2 LSTM layers\n",
        "model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "model.add(keras.layers.LSTM(32))\n",
        "\n",
        "# dense layer\n",
        "model.add(keras.layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "# output layer\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "saved_model=\"LSTM_mfcc_13_2048_512.weights.hdf5\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7kmDIAEgQ9A"
      },
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "checkpoint = ModelCheckpoint(weights_dir+saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cG0GLTrLhqgo"
      },
      "source": [
        "\n",
        "history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30, callbacks = callbacks_list, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7ThhfCHfIuK"
      },
      "source": [
        "history = model.fit(X_train, y_train, \n",
        "                    validation_split=0.1,\n",
        "                    epochs=60,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6nI8xqZ1nKN"
      },
      "source": [
        "model_loaded=tf.keras.models.load_model(weights_dir+\"cnn_3_class_stft.weights.hdf5\")\n",
        "#model_loaded.evaluate(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xf5IPasQGqYd"
      },
      "source": [
        "model.save(model_dir+\"cnn2D_stft.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0la0ZlzYmHSY"
      },
      "source": [
        "X_train_reshaped=np.reshape(X_train,newshape=(X_train.shape[0],X_train.shape[1],X_train.shape[2],1))\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# model.In\n",
        "model.add(Conv2D(filters = 128, kernel_size = (3,3), activation ='relu',input_shape=(X_train_reshaped.shape[1],X_train_reshaped.shape[2],X_train_reshaped.shape[3])))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 64, kernel_size = (3,3), activation ='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(MaxPooling2D(pool_size=(1,1)))\n",
        "\n",
        "model.add(tf.keras.layers.GlobalAveragePooling2D(name='GlobalPool'))\n",
        "\n",
        "model.add(Dense(16, activation = \"relu\")) #Fully connected layer\n",
        "model.add(Dense(5, activation = \"softmax\")) #Classification layer or output layer\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss='categorical_crossentropy', metrics=['acc'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "checkpoint = ModelCheckpoint(weights_dir+\"cnn2D_5_class_stft.weights.hdf5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yj8oz9jA3n3J"
      },
      "source": [
        "history = model.fit(X_train_reshaped, y_train, \n",
        "                    validation_split=0.1,\n",
        "                    epochs=60,\n",
        "                    verbose=1,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOsLiFsqh-Jx"
      },
      "source": [
        "X_test_reshaped=np.reshape(X_test,newshape=(X_test.shape[0],X_test.shape[1],X_test.shape[2],1))\n",
        "pickle.dump(X_test, open(test_dir+\"X_test_stffs_cnn2D.pkl\",'wb'))\n",
        "pickle.dump(y_test, open(test_dir+\"y_test_stffs_cnn2D.pkl\",'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gy6AEFncSkFV"
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBVInT7zTdl6"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7AxpsJtIU-j"
      },
      "source": [
        "\"\"\"\n",
        "model.fit_generator(generator=my_training_batch_generator,\n",
        "                   steps_per_epoch = int(len(X_train_filenames) / batch_size),\n",
        "                   epochs = 15,\n",
        "                   verbose = 1,\n",
        "                   validation_data = my_validation_batch_generator,\n",
        "                   validation_steps = int(len(X_val_filenames) / batch_size))\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CfZL9657kJze"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMeDZjl0S7xS"
      },
      "source": [
        "for i in range(500):\n",
        "  try:  \n",
        "    x=pickle.load(open(sampled_dir+\"economics_\"+str(i+1)+\".pkl\",'rb'))\n",
        "    if len(x)<3307500 :\n",
        "      x=np.append(x,np.zeros(3307500-len(x)))\n",
        "      print(str(i+1)+\" \"+str(x.shape))\n",
        "      pickle.dump(x,open(sampled_dir+\"economics_\"+str(i+1)+\".pkl\",'wb'))\n",
        "  except:\n",
        "    continue\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qyZ5KoX-ncEC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
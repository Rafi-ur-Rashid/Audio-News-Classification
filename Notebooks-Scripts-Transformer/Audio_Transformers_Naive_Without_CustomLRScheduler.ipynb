{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio-Transformers-Naive.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIddH4q-oweV"
      },
      "source": [
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from os import path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED=2245\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXpol-huwClL"
      },
      "source": [
        "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_hR4UlvvAyS",
        "outputId": "602a8df7-a556-406e-e963-9893640c80ea"
      },
      "source": [
        "PATH_SCRIPT = \"/content/drive/MyDrive/Audio classification/Notebooks-Mahim\"\n",
        "os.chdir(PATH_SCRIPT)\n",
        "print(os.getcwd())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1DGiPjXTUI4ejRejy9C8oe3nAQXI6AZIW/Audio classification/Notebooks-Mahim\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkVANMjAyYJ-"
      },
      "source": [
        "## For trying out different architectures, I am fitting with validation set, since X_train is very large, and subset is not available at the moment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0rkQPUrwGLQ",
        "outputId": "fa9fd257-4b4d-4762-a601-c1ee1854ce41"
      },
      "source": [
        "# X_train_file = \"/content/drive/MyDrive/Audio classification/mfccs/train_13_2048_512.pkl\"\n",
        "# Y_train_file = \"/content/drive/MyDrive/Audio classification/lables/train.pkl\"\n",
        "\n",
        "X_train_file = \"/content/drive/MyDrive/Audio classification/mfccs/val_13_2048_512.pkl\"\n",
        "Y_train_file = \"/content/drive/MyDrive/Audio classification/lables/val.pkl\"\n",
        "\n",
        "with open(X_train_file, mode='rb') as fin:\n",
        "    # X_train = pickle.load(fin)\n",
        "    X = pickle.load(fin)\n",
        "\n",
        "with open(Y_train_file, mode='rb') as fin:\n",
        "    # Y_train = pickle.load(fin)\n",
        "    Y = pickle.load(fin)\n",
        "\n",
        "print(X.shape, Y.shape)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7711, 1292, 13) (7711, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wN4Sv-Z10U7"
      },
      "source": [
        "# del X_train, Y_train"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVGgkQXQvhEC"
      },
      "source": [
        "## For now helper_script is kept in a single cell.\n",
        "## Will be used separately in Lab's Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "OjMDManYvPri"
      },
      "source": [
        "#@title Helper Script is kept here verbatim. Please Update from GitHub regularly !!\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "RANDOM_STATE = 2245\n",
        "\n",
        "LABELS_MAPPING_FORWARD = {\n",
        "    'national': 0,\n",
        "    'international': 1,\n",
        "    'economics': 2,\n",
        "    'entertainment': 3,\n",
        "    'sports': 4\n",
        "}\n",
        "\n",
        "LABELS_MAPPING_REVERSE = {\n",
        "    0: 'national', \n",
        "    1: 'international', \n",
        "    2: 'economics', \n",
        "    3: 'entertainment', \n",
        "    4: 'sports'\n",
        "}\n",
        "\n",
        "NUM_LABELS = len(LABELS_MAPPING_FORWARD)\n",
        "\n",
        "get_label_name = lambda label_id: LABELS_MAPPING_REVERSE.get(label_id)\n",
        "get_label_class_id = lambda name: LABELS_MAPPING_REVERSE.get(name)\n",
        "\n",
        "def get_various_metrics_and_print(Y_true, Y_predicted):\n",
        "    TN, FP, FN, TP = confusion_matrix(Y_true, Y_predicted).ravel()\n",
        "    accuracy = (TP + TN)/(TP+TN+FP+FN)\n",
        "    recall = (TP)/(TP + FN)\n",
        "    specificity = (TN)/(TN + FP) # TNR\n",
        "    false_positive_rate = (FP)/(TN + FP) # false_positive_rate = 1 - TNR\n",
        "    precision = (TP)/(TP + FP)\n",
        "    false_discovery_rate = (FP)/(TP + FP)\n",
        "    neg_predicted_val = (TN)/(TN + FN)\n",
        "    f1_score = 2*((precision * recall) / (precision + recall))\n",
        "\n",
        "    print(\"TN = \", TN, \" FP = \", FP, \" FN = \", FN, \" TP = \", TP)\n",
        "    print(\"Accuracy = \", accuracy*100, \"%\")\n",
        "    print(\"TPR = Sensitivity = Recall = \", recall*100, \"%\")\n",
        "    print(\"TNR = Specificity = \", specificity*100, \"%\")\n",
        "    print(\"Precision = PPV = Positive Predictive Value = \", precision*100, \"%\")\n",
        "    print(\"FDR = False Discovery Rate = \", false_discovery_rate*100, \"%\")\n",
        "    print(\"FPR = False Positive Rate = \", false_positive_rate*100, \"%\")\n",
        "    print(\"F1 Score = \", f1_score*100, \"%\")\n",
        "    print(\"Neg Predicted Val = \", neg_predicted_val*100, \"%\")\n",
        "    print(\"\\n\")\n",
        "    # c_report = classification_report(y_true=Y_true, y_pred=Y_predicted)\n",
        "    c_report = None\n",
        "    print(c_report)\n",
        "    return precision, recall, f1_score, c_report\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(Y_true=None, Y_predicted=None):\n",
        "  ## https://www.youtube.com/watch?v=T27WVIM8Xys\n",
        "    # mat = confusion_matrix(y_test,y_preds)\n",
        "    cf_matrix = confusion_matrix(Y_true, Y_predicted)\n",
        "    # cf_matrix = np.array([[23, 5], [3, 30]])\n",
        "    print(cf_matrix)\n",
        "    \n",
        "    # group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    group_names = ['TN','FP','FN','TP']\n",
        "    \n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
        "    \n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "    \n",
        "    # labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    \n",
        "    # sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
        "    #         fmt='.2%', cmap=plt.cm.magma)\n",
        "\n",
        "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=plt.cm.magma)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIECgvoKqEJh",
        "outputId": "da805e61-e601-4266-d2b2-cef00e6d2e86"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6168, 1292, 13) (6168, 5)\n",
            "(1543, 1292, 13) (1543, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTXbbVojymei"
      },
      "source": [
        "### Transformer For Audio Classification codes taken from the following GitHub [repository](https://github.com/facundodeza/transfomer-audio-classification/blob/master/audio_classification_transformer.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BuY7E4VvqEG-"
      },
      "source": [
        "#@title Full Transformer Code from above GitHub repository\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask zero out padding tokens.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  return tf.matmul(attention_weights, value)\n",
        "\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
        "    super(MultiHeadAttention, self).__init__(name=name)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model):\n",
        "    super(PositionalEncoding, self).__init__()\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "    \n",
        "# This allows to the transformer to know where there is real data and where it is padded\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def encoder_layer(units, d_model, num_heads, dropout,name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MultiHeadAttention(\n",
        "      d_model, num_heads, name=\"attention\")({\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "      })\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def encoder(time_steps,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            projection,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "  \n",
        "  if projection=='linear':\n",
        "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
        "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
        "    print('projection layer is linear')\n",
        "  \n",
        "  else:\n",
        "    projection=tf.identity(inputs) # Same layer repeat ?\n",
        "    print('projection layer is none')\n",
        "   \n",
        "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  projection = PositionalEncoding(time_steps, d_model)(projection)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        " \n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def transformer(time_steps,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                output_size,\n",
        "                projection,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  \n",
        "  \n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(tf.dtypes.cast(\n",
        "          \n",
        "    #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
        "    # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked      \n",
        "    tf.math.reduce_sum(\n",
        "    inputs,\n",
        "    axis=2,\n",
        "    keepdims=False,\n",
        "    name=None\n",
        "), tf.int32))\n",
        "  \n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      time_steps=time_steps,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      projection=projection,\n",
        "      name='encoder'\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  #We reshape for feeding our FC in the next step\n",
        "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
        "  \n",
        "  #We predict our class\n",
        "  outputs = tf.keras.layers.Dense(units=output_size, use_bias=True, activation='softmax', name=\"outputs\")(outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZO5Li5J6gvx",
        "outputId": "b32c3b11-5a71-4c57-fbc3-da18f31e7f19"
      },
      "source": [
        "print(f\"NUM_LABELS = {NUM_LABELS}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_LABELS = 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYtyTNI26y21"
      },
      "source": [
        "## TODO - Changes\n",
        "\n",
        "* Custom Learning Rate Scheduler of Transformer\n",
        "* No. of heads\n",
        "* No. of layers\n",
        "* Projection - Different features eg. Linear, None, Convolutional, etc.\n",
        "* **Beam Search** ?\n",
        "* Minimum Risk Training later on best model to be optimized on **f1** score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y77sJ1S8qEOg"
      },
      "source": [
        "NUM_LAYERS = 2\n",
        "D_MODEL = X.shape[2] # eg. X.shape = (7711, 1292, 13) -> D_MODEL = 13\n",
        "NUM_HEADS = 1 # 4\n",
        "UNITS = 1024\n",
        "DROPOUT = 0.1\n",
        "TIME_STEPS = X.shape[1] # TIME_STEPS -> 1292\n",
        "OUTPUT_SIZE = NUM_LABELS\n",
        "EPOCHS = 10\n",
        "# EXPERIMENTS=10\n",
        "projection = 'none'"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHbShj_z7Wkw",
        "outputId": "4cb6e014-a80b-436c-b6be-df3c68587cee"
      },
      "source": [
        "print(f\"d_model = {D_MODEL}, num_heads = {NUM_HEADS}\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_model = 13, num_heads = 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_hi8aSpqEMC",
        "outputId": "12ce95eb-99fe-4a51-b675-c0f5dee02b22"
      },
      "source": [
        "CKPT_DIRECTORY = \"CKPTS-June-25\"\n",
        "checkpoint = ModelCheckpoint(CKPT_DIRECTORY, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') ## need to monitor val_get_f1 ?\n",
        "callbacks_list = [checkpoint]\n",
        "\n",
        "model = transformer(\n",
        "    time_steps=TIME_STEPS,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    output_size=OUTPUT_SIZE,  \n",
        "    projection=projection\n",
        ")\n",
        "\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.000001), ## Need to implement custom LR Scheduler\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projection layer is none\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1-GEFxH8hWL",
        "outputId": "7fcd912c-30b7-49fa-db96-0e5956024c2a"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"audio_class\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "inputs (InputLayer)             [(None, None, 13)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.reduce_sum_2 (TFOpLambd (None, None)         0           inputs[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf.cast_2 (TFOpLambda)          (None, None)         0           tf.math.reduce_sum_2[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "enc_padding_mask (Lambda)       (None, 1, 1, None)   0           tf.cast_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "encoder (Functional)            (None, None, 13)     56882       inputs[0][0]                     \n",
            "                                                                 enc_padding_mask[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "tf.reshape_2 (TFOpLambda)       (None, 16796)        0           encoder[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "outputs (Dense)                 (None, 5)            83985       tf.reshape_2[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 140,867\n",
            "Trainable params: 140,867\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5H0D_ROy4dGE",
        "outputId": "f45316e4-9ba1-40cc-b25a-8533d112aa7c"
      },
      "source": [
        "history = model.fit(X_train, Y_train, \n",
        "                epochs=EPOCHS, \n",
        "                validation_data=(X_test, Y_test),\n",
        "                callbacks = callbacks_list, verbose=1)\n",
        "\n",
        "# model.save(MODEL_SAVE_FILE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "193/193 [==============================] - ETA: 0s - loss: 1.8940 - accuracy: 0.2579"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qI_9qYfqEQ-"
      },
      "source": [
        "Y_pred_0 = model.predict(X_test[0:1])\n",
        "print(Y_pred_0.shape)\n",
        "Y_pred_0 = Y_pred_0[0]\n",
        "print(Y_pred_0)\n",
        "print(np.argmax(Y_pred_0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAfTS81YMHkF"
      },
      "source": [
        "plt.plot(history)\n",
        "plt.xtitle(\"\")\n",
        "plt.ytitle(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBC57Q7oMHm6"
      },
      "source": [
        "Y_pred_test = model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_s_qGyGS39T"
      },
      "source": [
        "# get_various_metrics_and_print(Y_true=Y_test, Y_predicted=Y_pred_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kbduIdpS3_y"
      },
      "source": [
        "# with open(\"Y_pred_test.pkl\", mode='wb') as fout:\n",
        "#     pickle.dump(Y_pred_test, fout)\n",
        "\n",
        "# with open(\"Y_test.pkl\", mode='wb') as fout:\n",
        "#     pickle.dump(Y_test, fout)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dYNkfNTVbbO"
      },
      "source": [
        "Y_test_labeled = np.argmax(Y_test, axis=-1)\n",
        "Y_test_labeled = [get_label_name(id) for id in Y_test_labeled]\n",
        "print(Y_test_labeled)\n",
        "\n",
        "Y_pred_labeled = np.argmax(Y_pred_test, axis=-1)\n",
        "Y_pred_labeled = [get_label_name(id) for id in Y_pred_labeled]\n",
        "print(Y_pred_labeled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXxhNA8ZS4CT"
      },
      "source": [
        "c_report = classification_report(y_true=Y_test_labeled, y_pred=Y_pred_labeled)\n",
        "print(c_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmZWoDDOS4Eg"
      },
      "source": [
        "# confusion_matrix(y_true=Y_test_labeled, y_pred=Y_pred_labeled)\n",
        "\n",
        "# plot_confusion_matrix(Y_true=Y_test_labeled, Y_predicted=Y_pred_labeled)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgSRUn_gMHpb"
      },
      "source": [
        "np.unique(np.argmax(Y, axis=-1), return_counts=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWcsz4omMHsh"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXcF6S9PV6MZ"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFzTx0vcV6Pd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dA8ijx4V6R7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
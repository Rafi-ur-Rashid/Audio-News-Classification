{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio-Transformers-29June.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "QAdOOcfw89aq"
      },
      "source": [
        "#@title Import Statements\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from os import path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED=2245\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbNG6mqhBqkA"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.layers import (Input, GlobalAvgPool1D, Dense, Bidirectional, GRU, Dropout)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6vT5jP59BYf",
        "outputId": "90e2890d-81a2-4da2-d224-102efe56e9b9"
      },
      "source": [
        "PATH_SCRIPT = \"/content/drive/MyDrive/Audio classification/Notebooks-Mahim\"\n",
        "os.chdir(PATH_SCRIPT)\n",
        "print(os.getcwd())\n",
        "\n",
        "# X_train_file = \"/content/drive/MyDrive/Audio classification/mfccs/train_13_2048_512.pkl\"\n",
        "# Y_train_file = \"/content/drive/MyDrive/Audio classification/lables/train.pkl\"\n",
        "\n",
        "X_train_file = \"/content/drive/MyDrive/Audio classification/mfccs/val_16_2048_512.pkl\"\n",
        "Y_train_file = \"/content/drive/MyDrive/Audio classification/lables/val_16_2048_512.pkl\"\n",
        "\n",
        "with open(X_train_file, mode='rb') as fin:\n",
        "    # X_train = pickle.load(fin)\n",
        "    X = pickle.load(fin)\n",
        "    X = np.asarray(X)\n",
        "\n",
        "with open(Y_train_file, mode='rb') as fin:\n",
        "    # Y_train = pickle.load(fin)\n",
        "    Y = pickle.load(fin)\n",
        "    Y = np.asarray(Y)\n",
        "    Y = tf.keras.utils.to_categorical(Y)\n",
        "\n",
        "\n",
        "print(X.shape, Y.shape)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "## Load accordingly\n",
        "################################################################################\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, \n",
        "                                    test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_val.shape, Y_val.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1DGiPjXTUI4ejRejy9C8oe3nAQXI6AZIW/Audio classification/Notebooks-Mahim\n",
            "(8025, 1292, 16) (8025, 5)\n",
            "(6420, 1292, 16) (6420, 5)\n",
            "(1605, 1292, 16) (1605, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H45dCKpIUi3W"
      },
      "source": [
        "MODEL_SAVE_DIRECTORY = \"Transformers\"\n",
        "DATE = \"June29\"\n",
        "FILE_MODEL_PATH = \"{}/{}-Transformer.h5\".format(MODEL_SAVE_DIRECTORY, DATE)\n",
        "FILE_MODEL_CHECKPOINT_BEST = \"{}/{}-BestCKPT.h5\".format(MODEL_SAVE_DIRECTORY, DATE)\n",
        "\n",
        "print(f\"FILE_MODEL_PATH = {FILE_MODEL_PATH}\\nFILE_MODEL_CHECKPOINT_BEST = {FILE_MODEL_CHECKPOINT_BEST}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "rbOvF3di9BbQ"
      },
      "source": [
        "#@title Helper Script is kept here verbatim. Please Update from GitHub regularly !!\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "RANDOM_STATE = 2245\n",
        "\n",
        "LABELS_MAPPING_FORWARD = {\n",
        "    'national': 0,\n",
        "    'international': 1,\n",
        "    'economics': 2,\n",
        "    'entertainment': 3,\n",
        "    'sports': 4\n",
        "}\n",
        "\n",
        "LABELS_MAPPING_REVERSE = {\n",
        "    0: 'national', \n",
        "    1: 'international', \n",
        "    2: 'economics', \n",
        "    3: 'entertainment', \n",
        "    4: 'sports'\n",
        "}\n",
        "\n",
        "NUM_LABELS = len(LABELS_MAPPING_FORWARD)\n",
        "\n",
        "get_label_name = lambda label_id: LABELS_MAPPING_REVERSE.get(label_id)\n",
        "get_label_class_id = lambda name: LABELS_MAPPING_REVERSE.get(name)\n",
        "\n",
        "def get_various_metrics_and_print(Y_true, Y_predicted):\n",
        "    TN, FP, FN, TP = confusion_matrix(Y_true, Y_predicted).ravel()\n",
        "    accuracy = (TP + TN)/(TP+TN+FP+FN)\n",
        "    recall = (TP)/(TP + FN)\n",
        "    specificity = (TN)/(TN + FP) # TNR\n",
        "    false_positive_rate = (FP)/(TN + FP) # false_positive_rate = 1 - TNR\n",
        "    precision = (TP)/(TP + FP)\n",
        "    false_discovery_rate = (FP)/(TP + FP)\n",
        "    neg_predicted_val = (TN)/(TN + FN)\n",
        "    f1_score = 2*((precision * recall) / (precision + recall))\n",
        "\n",
        "    print(\"TN = \", TN, \" FP = \", FP, \" FN = \", FN, \" TP = \", TP)\n",
        "    print(\"Accuracy = \", accuracy*100, \"%\")\n",
        "    print(\"TPR = Sensitivity = Recall = \", recall*100, \"%\")\n",
        "    print(\"TNR = Specificity = \", specificity*100, \"%\")\n",
        "    print(\"Precision = PPV = Positive Predictive Value = \", precision*100, \"%\")\n",
        "    print(\"FDR = False Discovery Rate = \", false_discovery_rate*100, \"%\")\n",
        "    print(\"FPR = False Positive Rate = \", false_positive_rate*100, \"%\")\n",
        "    print(\"F1 Score = \", f1_score*100, \"%\")\n",
        "    print(\"Neg Predicted Val = \", neg_predicted_val*100, \"%\")\n",
        "    print(\"\\n\")\n",
        "    # c_report = classification_report(y_true=Y_true, y_pred=Y_predicted)\n",
        "    c_report = None\n",
        "    print(c_report)\n",
        "    return precision, recall, f1_score, c_report\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(Y_true=None, Y_predicted=None):\n",
        "  ## https://www.youtube.com/watch?v=T27WVIM8Xys\n",
        "    # mat = confusion_matrix(y_test,y_preds)\n",
        "    cf_matrix = confusion_matrix(Y_true, Y_predicted)\n",
        "    # cf_matrix = np.array([[23, 5], [3, 30]])\n",
        "    print(cf_matrix)\n",
        "    \n",
        "    # group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    group_names = ['TN','FP','FN','TP']\n",
        "    \n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
        "    \n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "    \n",
        "    # labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    \n",
        "    # sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
        "    #         fmt='.2%', cmap=plt.cm.magma)\n",
        "\n",
        "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=plt.cm.magma)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSh6bQuv9Bg6"
      },
      "source": [
        "## Checkpoints and other stuffs.\n",
        "h5_name = FILE_MODEL_CHECKPOINT_BEST\n",
        "# os.path.join(\"SAVED_THINGS\", \"transformer.h5\")\n",
        "\n",
        "checkpoint_single_path = ModelCheckpoint(\n",
        "        h5_name,\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode=\"max\",\n",
        "        save_weights_only=True,\n",
        "        # overwrite=True\n",
        ")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqrpqdsNDWoI"
      },
      "source": [
        "### Transformer For Audio Classification codes taken from the following GitHub [repository](https://github.com/facundodeza/transfomer-audio-classification/blob/master/audio_classification_transformer.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "BB9RHMKMDYUp"
      },
      "source": [
        "# @title Full Transformer Code from above GitHub repository\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask zero out padding tokens.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  return tf.matmul(attention_weights, value)\n",
        "\n",
        "\n",
        "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, **kwargs): # name='multi_head_attention'\n",
        "    super(MyMultiHeadAttention, self).__init__(**kwargs)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'd_model': self.d_model,\n",
        "        'num_heads': self.num_heads\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model, **kwargs): # , name=\"PositionalEncoding\"):\n",
        "    super(PositionalEncoding, self).__init__(**kwargs)\n",
        "    self.position = position\n",
        "    self.d_model = d_model\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "    # self.name = name\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'position': self.position,\n",
        "        'd_model': self.d_model\n",
        "        # 'name': self.name\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "    \n",
        "# This allows to the transformer to know where there is real data and where it is padded\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MyMultiHeadAttention(d_model, num_heads, name=\"attention\")(\n",
        "        {\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "        }\n",
        "    )\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def encoder(time_steps,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            projection,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "  \n",
        "  if projection=='linear':\n",
        "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
        "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
        "    print('projection layer is linear')\n",
        "  \n",
        "  else:\n",
        "    projection=tf.identity(inputs) # Same layer repeat ?\n",
        "    print('projection layer is none')\n",
        "   \n",
        "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  projection = PositionalEncoding(time_steps, d_model, name=\"PositionalEncoding\")(projection)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        " \n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def transformer(time_steps,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                output_size,\n",
        "                projection,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  \n",
        "  \n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(tf.dtypes.cast(\n",
        "          \n",
        "    #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
        "    # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked      \n",
        "    tf.math.reduce_sum(\n",
        "    inputs,\n",
        "    axis=2,\n",
        "    keepdims=False,\n",
        "    name=None\n",
        "), tf.int32))\n",
        "  \n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      time_steps=time_steps,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      projection=projection,\n",
        "      name='encoder'\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  #We reshape for feeding our FC in the next step\n",
        "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
        "  \n",
        "  #We predict our class\n",
        "  outputs = tf.keras.layers.Dense(units=output_size, use_bias=True, activation='softmax', name=\"outputs\")(outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')\n",
        "\n",
        "## https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf\n",
        "\n",
        "\n",
        "class CustomLearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000, name=None):\n",
        "        super(CustomLearningRateScheduler, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        ## https://github.com/tensorflow/tensorflow/issues/28799\n",
        "        # Basically, can't keep in compile time.\n",
        "        # self.d_model = tf.cast(self.d_model, tf.float32).numpy() ## Casting makes it unserializable ?\n",
        "        # self.d_model = tf.cast(self.d_model, tf.float32)## Casting makes it unserializable ?\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.name = name  # Modified from the source\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        # return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "        return tf.math.rsqrt(tf.cast(self.d_model, tf.float32)) * tf.math.minimum(arg1, arg2) # recast in runtime\n",
        "\n",
        "    def get_config(self):  # Modified from the source\n",
        "        return {\n",
        "            \"d_model\": self.d_model,\n",
        "            \"warmup_steps\": self.warmup_steps,\n",
        "            \"name\": self.name,\n",
        "        }"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5iDQy9XCVF5h"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yek1dQV5U6yQ"
      },
      "source": [
        "## Hyperparameter Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPfqVv-dO5I9",
        "outputId": "6c27b6ea-ca9b-4c7a-ad83-9327d204c808"
      },
      "source": [
        "EPOCHS = 50\n",
        "\n",
        "NUM_LAYERS = 6\n",
        "D_MODEL = X.shape[2] # eg. X.shape = (7711, 1292, 13) -> D_MODEL = 13\n",
        "NUM_HEADS = 4\n",
        "UNITS = 1024\n",
        "DROPOUT = 0.1\n",
        "TIME_STEPS = X.shape[1] # TIME_STEPS -> 1292\n",
        "OUTPUT_SIZE = NUM_LABELS\n",
        "# EXPERIMENTS=10\n",
        "projection = 'none'\n",
        "\n",
        "print(f\"d_model = {D_MODEL}, num_heads = {NUM_HEADS}\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_model = 16, num_heads = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yKibJMBDYXI",
        "outputId": "e4a7084f-b21a-4907-a23b-ae7cec2f4b19"
      },
      "source": [
        "model = transformer(\n",
        "    time_steps=TIME_STEPS,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    output_size=OUTPUT_SIZE,  \n",
        "    projection=projection\n",
        ")\n",
        "\n",
        "# CKPT_DIRECTORY = \"CKPTS-June-27\"\n",
        "# checkpoint = ModelCheckpoint(CKPT_DIRECTORY, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') ## need to monitor val_get_f1 ?\n",
        "callbacks_list = [checkpoint_single_path] # , callback_lr]\n",
        "\n",
        "# CustomLearningRateScheduler(d_model=D_MODEL)\n",
        "\n",
        "lr_schedule = CustomLearningRateScheduler(d_model=D_MODEL)\n",
        "optimizer_adam_custom = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(optimizer=optimizer_adam_custom,\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print(model.summary())\n",
        "history = model.fit(X_train, Y_train, epochs=EPOCHS, validation_data=(X_val, Y_val), callbacks=callbacks_list, verbose=1)\n",
        "\n",
        "model.save(FILE_MODEL_PATH)\n",
        "print(f\"Model Saved to {FILE_MODEL_PATH}\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projection layer is none\n",
            "Saved\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.6021 - accuracy: 0.4000 - val_loss: 2.4311 - val_accuracy: 0.2000\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.30000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.7706 - accuracy: 0.3000 - val_loss: 2.4128 - val_accuracy: 0.2000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EI-TZfqEPp1"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjOEfPTvFLwA"
      },
      "source": [
        "## Testing loading and reload weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7MnkE6nEPsp"
      },
      "source": [
        "new_model = keras.models.load_model(FILE_MODEL_PATH, \n",
        "custom_objects={\n",
        "    'PositionalEncoding': PositionalEncoding,\n",
        "    'MyMultiHeadAttention': MyMultiHeadAttention\n",
        "})"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXUpJGUyEPxV"
      },
      "source": [
        "new_model.load_weights(h5_name)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikWzO85j9B4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81u5DV7V9do_"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kPK62Zt9B7G"
      },
      "source": [
        "# print(np.unique(np.argmax(Y, axis=-1), return_counts=True))\n",
        "\n",
        "# Y_pred_test = model.predict(X_test)\n",
        "\n",
        "\n",
        "# Y_test_labeled = np.argmax(Y_test, axis=-1)\n",
        "# Y_test_labeled = [get_label_name(id) for id in Y_test_labeled]\n",
        "# print(Y_test_labeled)\n",
        "\n",
        "# Y_pred_labeled = np.argmax(Y_pred_test, axis=-1)\n",
        "# Y_pred_labeled = [get_label_name(id) for id in Y_pred_labeled]\n",
        "# print(Y_pred_labeled)\n",
        "\n",
        "# c_report = classification_report(y_true=Y_test_labeled, y_pred=Y_pred_labeled)\n",
        "# print(c_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgKMMa-29emT"
      },
      "source": [
        "# plt.plot(history.history['loss'])\n",
        "# plt.plot(history.history['val_loss'])\n",
        "# plt.title('Model Loss')\n",
        "# plt.ylabel('loss')\n",
        "# plt.xlabel('epoch')\n",
        "# plt.legend(['train', 'val'], loc='upper left')\n",
        "# plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luxen_6C9euj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
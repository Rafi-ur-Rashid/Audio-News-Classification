{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Audio-Transformers-29June.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "QAdOOcfw89aq"
      },
      "source": [
        "#@title Import Statements\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from os import path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED=2245\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gpu_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "for device in gpu_devices:\n",
        "    tf.config.experimental.set_memory_growth(device, True)\n",
        "    "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbNG6mqhBqkA"
      },
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.keras.layers import (Input, GlobalAvgPool1D, Dense, Bidirectional, GRU, Dropout)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6vT5jP59BYf",
        "outputId": "90e2890d-81a2-4da2-d224-102efe56e9b9"
      },
      "source": [
        "PATH_SCRIPT = \"/content/drive/MyDrive/Audio classification/Notebooks-Mahim\"\n",
        "os.chdir(PATH_SCRIPT)\n",
        "print(os.getcwd())\n",
        "\n",
        "# X_train_file = \"/content/drive/MyDrive/Audio classification/mfccs/train_13_2048_512.pkl\"\n",
        "# Y_train_file = \"/content/drive/MyDrive/Audio classification/lables/train.pkl\"\n",
        "\n",
        "X_train_file = \"/content/drive/MyDrive/Audio classification/mfccs/val_16_2048_512.pkl\"\n",
        "Y_train_file = \"/content/drive/MyDrive/Audio classification/lables/val_16_2048_512.pkl\"\n",
        "\n",
        "with open(X_train_file, mode='rb') as fin:\n",
        "    # X_train = pickle.load(fin)\n",
        "    X = pickle.load(fin)\n",
        "    X = np.asarray(X)\n",
        "\n",
        "with open(Y_train_file, mode='rb') as fin:\n",
        "    # Y_train = pickle.load(fin)\n",
        "    Y = pickle.load(fin)\n",
        "    Y = np.asarray(Y)\n",
        "    Y = tf.keras.utils.to_categorical(Y)\n",
        "\n",
        "\n",
        "print(X.shape, Y.shape)\n",
        "\n",
        "\n",
        "################################################################################\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, \n",
        "                                    test_size=0.2, random_state=RANDOM_STATE)\n",
        "\n",
        "print(X_train.shape, Y_train.shape)\n",
        "print(X_test.shape, Y_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1DGiPjXTUI4ejRejy9C8oe3nAQXI6AZIW/Audio classification/Notebooks-Mahim\n",
            "(8025, 1292, 16) (8025, 5)\n",
            "(6420, 1292, 16) (6420, 5)\n",
            "(1605, 1292, 16) (1605, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "rbOvF3di9BbQ"
      },
      "source": [
        "#@title Helper Script is kept here verbatim. Please Update from GitHub regularly !!\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "RANDOM_STATE = 2245\n",
        "\n",
        "LABELS_MAPPING_FORWARD = {\n",
        "    'national': 0,\n",
        "    'international': 1,\n",
        "    'economics': 2,\n",
        "    'entertainment': 3,\n",
        "    'sports': 4\n",
        "}\n",
        "\n",
        "LABELS_MAPPING_REVERSE = {\n",
        "    0: 'national', \n",
        "    1: 'international', \n",
        "    2: 'economics', \n",
        "    3: 'entertainment', \n",
        "    4: 'sports'\n",
        "}\n",
        "\n",
        "NUM_LABELS = len(LABELS_MAPPING_FORWARD)\n",
        "\n",
        "get_label_name = lambda label_id: LABELS_MAPPING_REVERSE.get(label_id)\n",
        "get_label_class_id = lambda name: LABELS_MAPPING_REVERSE.get(name)\n",
        "\n",
        "def get_various_metrics_and_print(Y_true, Y_predicted):\n",
        "    TN, FP, FN, TP = confusion_matrix(Y_true, Y_predicted).ravel()\n",
        "    accuracy = (TP + TN)/(TP+TN+FP+FN)\n",
        "    recall = (TP)/(TP + FN)\n",
        "    specificity = (TN)/(TN + FP) # TNR\n",
        "    false_positive_rate = (FP)/(TN + FP) # false_positive_rate = 1 - TNR\n",
        "    precision = (TP)/(TP + FP)\n",
        "    false_discovery_rate = (FP)/(TP + FP)\n",
        "    neg_predicted_val = (TN)/(TN + FN)\n",
        "    f1_score = 2*((precision * recall) / (precision + recall))\n",
        "\n",
        "    print(\"TN = \", TN, \" FP = \", FP, \" FN = \", FN, \" TP = \", TP)\n",
        "    print(\"Accuracy = \", accuracy*100, \"%\")\n",
        "    print(\"TPR = Sensitivity = Recall = \", recall*100, \"%\")\n",
        "    print(\"TNR = Specificity = \", specificity*100, \"%\")\n",
        "    print(\"Precision = PPV = Positive Predictive Value = \", precision*100, \"%\")\n",
        "    print(\"FDR = False Discovery Rate = \", false_discovery_rate*100, \"%\")\n",
        "    print(\"FPR = False Positive Rate = \", false_positive_rate*100, \"%\")\n",
        "    print(\"F1 Score = \", f1_score*100, \"%\")\n",
        "    print(\"Neg Predicted Val = \", neg_predicted_val*100, \"%\")\n",
        "    print(\"\\n\")\n",
        "    # c_report = classification_report(y_true=Y_true, y_pred=Y_predicted)\n",
        "    c_report = None\n",
        "    print(c_report)\n",
        "    return precision, recall, f1_score, c_report\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(Y_true=None, Y_predicted=None):\n",
        "  ## https://www.youtube.com/watch?v=T27WVIM8Xys\n",
        "    # mat = confusion_matrix(y_test,y_preds)\n",
        "    cf_matrix = confusion_matrix(Y_true, Y_predicted)\n",
        "    # cf_matrix = np.array([[23, 5], [3, 30]])\n",
        "    print(cf_matrix)\n",
        "    \n",
        "    # group_names = ['True Neg','False Pos','False Neg','True Pos']\n",
        "    group_names = ['TN','FP','FN','TP']\n",
        "    \n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
        "    \n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
        "    \n",
        "    # labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
        "\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    \n",
        "    # sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True, \n",
        "    #         fmt='.2%', cmap=plt.cm.magma)\n",
        "\n",
        "    sns.heatmap(cf_matrix, annot=labels, fmt='', cmap=plt.cm.magma)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwRSQVhQ9BeG"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmW5vblm9sOn"
      },
      "source": [
        "#### Transformer model taken from [music_genre_classification_GitHub](https://github.com/CVxTz/music_genre_classification/blob/master/code/trsf_genre_classification.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqTe7CZr-mUW"
      },
      "source": [
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis], np.arange(d_model)[np.newaxis, :], d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n",
        "\n",
        "\n",
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"Calculate the attention weights.\n",
        "    q, k, v must have matching leading dimensions.\n",
        "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
        "    The mask has different shapes depending on its type(padding or look ahead)\n",
        "    but it must be broadcastable for addition.\n",
        "    Args:\n",
        "      q: query shape == (..., seq_len_q, depth)\n",
        "      k: key shape == (..., seq_len_k, depth)\n",
        "      v: value shape == (..., seq_len_v, depth_v)\n",
        "      mask: Float tensor with shape broadcastable\n",
        "            to (..., seq_len_q, seq_len_k). Defaults to None.\n",
        "    Returns:\n",
        "      output, attention_weights\n",
        "    \"\"\"\n",
        "\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor.\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += mask * -1e9\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    \n",
        "    attention_weights = tf.nn.softmax(\n",
        "        scaled_attention_logits, axis=-1\n",
        "    )  # (..., seq_len_q, seq_len_k)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
        "\n",
        "    return output # , attention_weights\n",
        "\n",
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "\n",
        "    def call(self, v, k, q, mask=None):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask\n",
        "        )\n",
        "\n",
        "        scaled_attention = tf.transpose(\n",
        "            scaled_attention, perm=[0, 2, 1, 3]\n",
        "        )  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(\n",
        "            scaled_attention, (batch_size, -1, self.d_model)\n",
        "        )  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential(\n",
        "        [\n",
        "            tf.keras.layers.Dense(dff, activation=\"relu\"),  # (batch_size, seq_len, dff)\n",
        "            tf.keras.layers.Dense(d_model),  # (batch_size, seq_len, d_model)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "\n",
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(\n",
        "            out1 + ffn_output\n",
        "        )  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n",
        "\n",
        "\n",
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(\n",
        "        self, num_layers, d_model, num_heads, dff, maximum_position_encoding, rate=0.1,\n",
        "    ):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [\n",
        "            EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)\n",
        "        ]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training=None, mask=None):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x  # (batch_size, input_seq_len, d_model)\n",
        "\n",
        "\n",
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000, name=None):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.name = name  # Modified from the source\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "    def get_config(self):  # Modified from the source\n",
        "        return {\n",
        "            \"d_model\": self.d_model,\n",
        "            \"warmup_steps\": self.warmup_steps,\n",
        "            \"name\": self.name,\n",
        "        }"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shvyYV2--d-J"
      },
      "source": [
        "def get_transformer_pretrain(\n",
        "    num_layers=4, d_model=128, num_heads=8, dff=256, maximum_position_encoding=2048,\n",
        "):\n",
        "    inp = Input((None, d_model))\n",
        "\n",
        "    encoder = Encoder(\n",
        "        num_layers=num_layers,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dff=dff,\n",
        "        maximum_position_encoding=maximum_position_encoding,\n",
        "        rate=0.3,\n",
        "    )\n",
        "\n",
        "    x = encoder(inp)\n",
        "\n",
        "    out = Dense(d_model, activation=\"linear\", name=\"out_pretraining\")(x)\n",
        "\n",
        "    model = Model(inputs=inp, outputs=out)\n",
        "\n",
        "    opt = Adam(0.0001) # Need Custom LR\n",
        "\n",
        "    model.compile(optimizer=opt, loss=mae)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    return model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2soZ8X8DWJG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSh6bQuv9Bg6"
      },
      "source": [
        "## Checkpoints and other stuffs.\n",
        "h5_name = os.path.join(\"SAVED_THINGS\", \"transformer.h5\")\n",
        "\n",
        "checkpoint_single_path = ModelCheckpoint(\n",
        "        h5_name,\n",
        "        monitor=\"val_accuracy\",\n",
        "        verbose=1,\n",
        "        save_best_only=True,\n",
        "        mode=\"max\",\n",
        "        save_weights_only=True,\n",
        "        # overwrite=True\n",
        ")"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uvf9mzvNDWLq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzVOtinYDWOG"
      },
      "source": [
        ""
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqrpqdsNDWoI"
      },
      "source": [
        "## Other Notebook's Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB9RHMKMDYUp"
      },
      "source": [
        "## @title Full Transformer Code from above GitHub repository\n",
        "\n",
        "def scaled_dot_product_attention(query, key, value, mask):\n",
        "  matmul_qk = tf.matmul(query, key, transpose_b=True)\n",
        "\n",
        "  depth = tf.cast(tf.shape(key)[-1], tf.float32)\n",
        "  logits = matmul_qk / tf.math.sqrt(depth)\n",
        "\n",
        "  # add the mask zero out padding tokens.\n",
        "  if mask is not None:\n",
        "    logits += (mask * -1e9)\n",
        "\n",
        "  attention_weights = tf.nn.softmax(logits, axis=-1)\n",
        "\n",
        "  return tf.matmul(attention_weights, value)\n",
        "\n",
        "\n",
        "class MyMultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, d_model, num_heads, **kwargs): # name='multi_head_attention'\n",
        "    super(MyMultiHeadAttention, self).__init__(**kwargs)\n",
        "    self.num_heads = num_heads\n",
        "    self.d_model = d_model\n",
        "\n",
        "    assert d_model % self.num_heads == 0\n",
        "\n",
        "    self.depth = d_model // self.num_heads\n",
        "\n",
        "    self.query_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.key_dense = tf.keras.layers.Dense(units=d_model)\n",
        "    self.value_dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "    self.dense = tf.keras.layers.Dense(units=d_model)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'd_model': self.d_model,\n",
        "        'num_heads': self.num_heads\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def split_heads(self, inputs, batch_size):\n",
        "    inputs = tf.reshape(\n",
        "        inputs, shape=(batch_size, -1, self.num_heads, self.depth))\n",
        "    return tf.transpose(inputs, perm=[0, 2, 1, 3])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    query, key, value, mask = inputs['query'], inputs['key'], inputs[\n",
        "        'value'], inputs['mask']\n",
        "    batch_size = tf.shape(query)[0]\n",
        "\n",
        "    # linear layers\n",
        "    query = self.query_dense(query)\n",
        "    key = self.key_dense(key)\n",
        "    value = self.value_dense(value)\n",
        "\n",
        "    # split heads\n",
        "    query = self.split_heads(query, batch_size)\n",
        "    key = self.split_heads(key, batch_size)\n",
        "    value = self.split_heads(value, batch_size)\n",
        "\n",
        "    scaled_attention = scaled_dot_product_attention(query, key, value, mask)\n",
        "\n",
        "    scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "    concat_attention = tf.reshape(scaled_attention,\n",
        "                                  (batch_size, -1, self.d_model))\n",
        "\n",
        "    outputs = self.dense(concat_attention)\n",
        "\n",
        "    return outputs\n",
        "\n",
        "class PositionalEncoding(tf.keras.layers.Layer):\n",
        "\n",
        "  def __init__(self, position, d_model, **kwargs): # , name=\"PositionalEncoding\"):\n",
        "    super(PositionalEncoding, self).__init__(**kwargs)\n",
        "    self.position = position\n",
        "    self.d_model = d_model\n",
        "    self.pos_encoding = self.positional_encoding(position, d_model)\n",
        "    # self.name = name\n",
        "\n",
        "  def get_config(self):\n",
        "    config = super().get_config().copy()\n",
        "    config.update({\n",
        "        'position': self.position,\n",
        "        'd_model': self.d_model\n",
        "        # 'name': self.name\n",
        "    })\n",
        "    return config\n",
        "\n",
        "  def get_angles(self, position, i, d_model):\n",
        "    angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
        "    return position * angles\n",
        "\n",
        "  def positional_encoding(self, position, d_model):\n",
        "    angle_rads = self.get_angles(\n",
        "        position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
        "        i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
        "        d_model=d_model)\n",
        "    # apply sin to even index in the array\n",
        "    sines = tf.math.sin(angle_rads[:, 0::2])\n",
        "    # apply cos to odd index in the array\n",
        "    cosines = tf.math.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
        "    pos_encoding = pos_encoding[tf.newaxis, ...]\n",
        "    return tf.cast(pos_encoding, tf.float32)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
        "\n",
        "    \n",
        "# This allows to the transformer to know where there is real data and where it is padded\n",
        "def create_padding_mask(seq):\n",
        "  seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "  \n",
        "  # add extra dimensions to add the padding\n",
        "  # to the attention logits.\n",
        "  return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)\n",
        "\n",
        "def encoder_layer(units, d_model, num_heads, dropout, name=\"encoder_layer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model ), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "\n",
        "  attention = MyMultiHeadAttention(d_model, num_heads, name=\"attention\")(\n",
        "        {\n",
        "          'query': inputs,\n",
        "          'key': inputs,\n",
        "          'value': inputs,\n",
        "          'mask': padding_mask\n",
        "        }\n",
        "    )\n",
        "  attention = tf.keras.layers.Dropout(rate=dropout)(attention)\n",
        "  attention = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(inputs + attention)\n",
        "\n",
        "  outputs = tf.keras.layers.Dense(units=units, activation='relu')(attention)\n",
        "  outputs = tf.keras.layers.Dense(units=d_model)(outputs)\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(outputs)\n",
        "  outputs = tf.keras.layers.LayerNormalization(\n",
        "      epsilon=1e-6)(attention + outputs)\n",
        "\n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def encoder(time_steps,\n",
        "            num_layers,\n",
        "            units,\n",
        "            d_model,\n",
        "            num_heads,\n",
        "            dropout,\n",
        "            projection,\n",
        "            name=\"encoder\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  padding_mask = tf.keras.Input(shape=(1, 1, None), name=\"padding_mask\")\n",
        "  \n",
        "  if projection=='linear':\n",
        "    ## We implement a linear projection based on Very Deep Self-Attention Networks for End-to-End Speech Recognition. Retrieved from https://arxiv.org/abs/1904.13377\n",
        "    projection=tf.keras.layers.Dense( d_model,use_bias=True, activation='linear')(inputs)\n",
        "    print('projection layer is linear')\n",
        "  \n",
        "  else:\n",
        "    projection=tf.identity(inputs) # Same layer repeat ?\n",
        "    print('projection layer is none')\n",
        "   \n",
        "  projection *= tf.math.sqrt(tf.cast(d_model, tf.float32))\n",
        "  projection = PositionalEncoding(time_steps, d_model, name=\"PositionalEncoding\")(projection)\n",
        "\n",
        "  outputs = tf.keras.layers.Dropout(rate=dropout)(projection)\n",
        "\n",
        "  for i in range(num_layers):\n",
        "    outputs = encoder_layer(\n",
        "        units=units,\n",
        "        d_model=d_model,\n",
        "        num_heads=num_heads,\n",
        "        dropout=dropout,\n",
        "        name=\"encoder_layer_{}\".format(i),\n",
        "    )([outputs, padding_mask])\n",
        " \n",
        "  return tf.keras.Model(\n",
        "      inputs=[inputs, padding_mask], outputs=outputs, name=name)\n",
        "  \n",
        "def transformer(time_steps,\n",
        "                num_layers,\n",
        "                units,\n",
        "                d_model,\n",
        "                num_heads,\n",
        "                dropout,\n",
        "                output_size,\n",
        "                projection,\n",
        "                name=\"transformer\"):\n",
        "  inputs = tf.keras.Input(shape=(None,d_model), name=\"inputs\")\n",
        "  \n",
        "  \n",
        "  enc_padding_mask = tf.keras.layers.Lambda(\n",
        "      create_padding_mask, output_shape=(1, 1, None),\n",
        "      name='enc_padding_mask')(tf.dtypes.cast(\n",
        "          \n",
        "    #Like our input has a dimension of length X d_model but the masking is applied to a vector\n",
        "    # We get the sum for each row and result is a vector. So, if result is 0 it is because in that position was masked      \n",
        "    tf.math.reduce_sum(\n",
        "    inputs,\n",
        "    axis=2,\n",
        "    keepdims=False,\n",
        "    name=None\n",
        "), tf.int32))\n",
        "  \n",
        "\n",
        "  enc_outputs = encoder(\n",
        "      time_steps=time_steps,\n",
        "      num_layers=num_layers,\n",
        "      units=units,\n",
        "      d_model=d_model,\n",
        "      num_heads=num_heads,\n",
        "      dropout=dropout,\n",
        "      projection=projection,\n",
        "      name='encoder'\n",
        "  )(inputs=[inputs, enc_padding_mask])\n",
        "\n",
        "  #We reshape for feeding our FC in the next step\n",
        "  outputs=tf.reshape(enc_outputs,(-1,time_steps*d_model))\n",
        "  \n",
        "  #We predict our class\n",
        "  outputs = tf.keras.layers.Dense(units=output_size, use_bias=True, activation='softmax', name=\"outputs\")(outputs)\n",
        "\n",
        "  return tf.keras.Model(inputs=[inputs], outputs=outputs, name='audio_class')"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc1ge6QVNVcI"
      },
      "source": [
        "## https://stackoverflow.com/questions/58678836/notimplementederror-layers-with-arguments-in-init-must-override-get-conf\n",
        "\n",
        "\n",
        "class CustomLearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000, name=None):\n",
        "        super(CustomLearningRateScheduler, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "\n",
        "        ## https://github.com/tensorflow/tensorflow/issues/28799\n",
        "        # Basically, can't keep in compile time.\n",
        "        # self.d_model = tf.cast(self.d_model, tf.float32).numpy() ## Casting makes it unserializable ?\n",
        "        # self.d_model = tf.cast(self.d_model, tf.float32)## Casting makes it unserializable ?\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.name = name  # Modified from the source\n",
        "\n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        # return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n",
        "        return tf.math.rsqrt(tf.cast(self.d_model, tf.float32)) * tf.math.minimum(arg1, arg2) # recast in runtime\n",
        "\n",
        "    def get_config(self):  # Modified from the source\n",
        "        return {\n",
        "            \"d_model\": self.d_model,\n",
        "            \"warmup_steps\": self.warmup_steps,\n",
        "            \"name\": self.name,\n",
        "        }"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPfqVv-dO5I9",
        "outputId": "6c27b6ea-ca9b-4c7a-ad83-9327d204c808"
      },
      "source": [
        "NUM_LAYERS = 2\n",
        "D_MODEL = X.shape[2] # eg. X.shape = (7711, 1292, 13) -> D_MODEL = 13\n",
        "NUM_HEADS = 2 # 4\n",
        "UNITS = 1024\n",
        "DROPOUT = 0.1\n",
        "TIME_STEPS = X.shape[1] # TIME_STEPS -> 1292\n",
        "OUTPUT_SIZE = NUM_LABELS\n",
        "EPOCHS = 10\n",
        "# EXPERIMENTS=10\n",
        "projection = 'none'\n",
        "\n",
        "print(f\"d_model = {D_MODEL}, num_heads = {NUM_HEADS}\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "d_model = 16, num_heads = 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yKibJMBDYXI",
        "outputId": "e4a7084f-b21a-4907-a23b-ae7cec2f4b19"
      },
      "source": [
        "model = transformer(\n",
        "    time_steps=TIME_STEPS,\n",
        "    num_layers=NUM_LAYERS,\n",
        "    units=UNITS,\n",
        "    d_model=D_MODEL,\n",
        "    num_heads=NUM_HEADS,\n",
        "    dropout=DROPOUT,\n",
        "    output_size=OUTPUT_SIZE,  \n",
        "    projection=projection\n",
        ")\n",
        "\n",
        "# CKPT_DIRECTORY = \"CKPTS-June-27\"\n",
        "# checkpoint = ModelCheckpoint(CKPT_DIRECTORY, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max') ## need to monitor val_get_f1 ?\n",
        "callbacks_list = [checkpoint_single_path] # , callback_lr]\n",
        "\n",
        "# CustomLearningRateScheduler(d_model=D_MODEL)\n",
        "\n",
        "\n",
        "\n",
        "lr_schedule = CustomLearningRateScheduler(d_model=D_MODEL)\n",
        "optimizer_adam_custom = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "model.compile(optimizer=optimizer_adam_custom,\n",
        "              loss='categorical_crossentropy', \n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# print(model.summary())\n",
        "model.save(\"MODEL.h5\")\n",
        "# tf.keras.models.save_model( model, \"MODEL.h5\", overwrite=True, include_optimizer=True, save_format=None )\n",
        "# # model.to_json(\"MODEL.json\")\n",
        "print(\"Saved\")\n",
        "\n",
        "history = model.fit(X_train[0:10], Y_train[0:10], epochs=2, validation_data=(X_test[0:10], Y_test[0:10]), callbacks = callbacks_list, verbose=1)"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projection layer is none\n",
            "Saved\n",
            "Epoch 1/2\n",
            "1/1 [==============================] - 5s 5s/step - loss: 1.6021 - accuracy: 0.4000 - val_loss: 2.4311 - val_accuracy: 0.2000\n",
            "\n",
            "Epoch 00001: val_accuracy did not improve from 0.30000\n",
            "Epoch 2/2\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.7706 - accuracy: 0.3000 - val_loss: 2.4128 - val_accuracy: 0.2000\n",
            "\n",
            "Epoch 00002: val_accuracy did not improve from 0.30000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EI-TZfqEPp1"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjOEfPTvFLwA"
      },
      "source": [
        "## Testing loading and reload weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7MnkE6nEPsp"
      },
      "source": [
        "new_model = keras.models.load_model(\"MODEL.h5\", \n",
        "custom_objects={\n",
        "    'PositionalEncoding': PositionalEncoding,\n",
        "    'MyMultiHeadAttention': MyMultiHeadAttention\n",
        "})"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXUpJGUyEPxV"
      },
      "source": [
        "new_model.load_weights(h5_name)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0Y_JLocEPze"
      },
      "source": [
        "# for l1, l2, i in zip(model.layers, new_model.layers, np.arange(0, len(new_model.layers))):\n",
        "#     print(f\"Check for idx {i}\")\n",
        "\n",
        "#     if len(l1.weights) > 0 and len(l2.weights) > 0:\n",
        "#         print((l1.weights == l2.weights).any())"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tgcIvLwEOfC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cek3PFJ3EOiU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-El-TtM7EOl1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtyY7ikcEOoK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv8GpEBL9Bjs"
      },
      "source": [
        "# model.fit -> use as param: callbacks=[checkpoint]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQfK5SPm9BnA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVkplP8H9Bp4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBhdzLbt9Bs8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XM7SL_N9Bvg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "us0PhsFN9ByZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKFjO8hz9B1b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikWzO85j9B4t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81u5DV7V9do_"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2kPK62Zt9B7G"
      },
      "source": [
        "print(np.unique(np.argmax(Y, axis=-1), return_counts=True))\n",
        "\n",
        "Y_pred_test = model.predict(X_test)\n",
        "\n",
        "\n",
        "Y_test_labeled = np.argmax(Y_test, axis=-1)\n",
        "Y_test_labeled = [get_label_name(id) for id in Y_test_labeled]\n",
        "print(Y_test_labeled)\n",
        "\n",
        "Y_pred_labeled = np.argmax(Y_pred_test, axis=-1)\n",
        "Y_pred_labeled = [get_label_name(id) for id in Y_pred_labeled]\n",
        "print(Y_pred_labeled)\n",
        "\n",
        "c_report = classification_report(y_true=Y_test_labeled, y_pred=Y_pred_labeled)\n",
        "print(c_report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgKMMa-29emT"
      },
      "source": [
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seuoYawn9epF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRvHrTya9eri"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luxen_6C9euj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer-Fit_Generator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhm35aJ9ISz-"
      },
      "source": [
        "# Convert train.pkl into 1.pkl, 2.pkl, etc."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IbACGjmpwkoU"
      },
      "source": [
        "# Use model.fit_generator for LSTM firstly, then check using Transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHRk9siDoS63"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import IPython.display as ipd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "from os import path\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "RANDOM_SEED=2245\n",
        "from numpy.random import seed\n",
        "seed(RANDOM_SEED)\n",
        "tf.random.set_seed(RANDOM_SEED)\n",
        "\n",
        "from sklearn.metrics import recall_score"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fROId8MYoRDW"
      },
      "source": [
        "def load_pickle(file_name):\n",
        "    with open(file_name, mode='rb') as fin:\n",
        "        return pickle.load(fin)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TH7FFISOpmvK"
      },
      "source": [
        "def save_pickle(obj, file_name):\n",
        "    with open(file_name, mode='wb') as fout:\n",
        "        pickle.dump(obj, fout)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-V8231ty-Sq"
      },
      "source": [
        "BASE_FOLDER = os.path.join(\"/content/drive/MyDrive/Audio classification/mfccs/For-Generator\", \"train_16_2048_512\")\n",
        "LABELS_FILE = \"/content/drive/MyDrive/Audio classification/labels/train_16_2048_512.pkl\"\n",
        "\n",
        "WEIGHTS_FILE = os.path.join(\"/content/drive/MyDrive/Audio classification/Notebooks-Mahim/WEIGHTS_TESTING\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52QuNAqo3VCS",
        "outputId": "f378890b-2f8b-4a3a-f61f-5c8fb2b13427"
      },
      "source": [
        "get_name_pickle = lambda cnt: os.path.join(BASE_FOLDER, \"{}.pkl\").format(str(cnt))\n",
        "\n",
        "print(get_name_pickle(1))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Audio classification/mfccs/For-Generator/train_16_2048_512/1.pkl\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUrEZdxxwlyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "491e4cc8-e25c-4b7d-f098-99dceb60e21b"
      },
      "source": [
        "files = os.listdir(BASE_FOLDER)\n",
        "print(files[0])\n",
        "X_0 = load_pickle(os.path.join(BASE_FOLDER, files[0]))\n",
        "print(X_0.shape)\n",
        "print(f\"len files = {len(files)}\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34561.pkl\n",
            "(1292, 16)\n",
            "len files = 35560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctIHxqIi8Cy_",
        "outputId": "1168f9af-10cd-40e7-99cd-a852be86106e"
      },
      "source": [
        "print(\"DUMMY MAKING Y_TRAIN\")\n",
        "Y_train = [np.random.randint(low=0, high=5) for _ in range(len(files))] # high is exclusive\n",
        "Y_train = tf.keras.utils.to_categorical(Y_train)\n",
        "print(Y_train.shape, Y_train[0])"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DUMMY MAKING Y_TRAIN\n",
            "(35560, 5) [1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K-h_7L530B6F"
      },
      "source": [
        "## LSTM Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Refen-Zx0L4V"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI1ThzGmzBGt",
        "outputId": "9f9fb0a5-1919-4591-c970-65934ca3bfcd"
      },
      "source": [
        "# input_shape = (X_train.shape[1], X_train.shape[2]) # X_train: batch_size, x[0], x[1]\n",
        "input_shape = (X_0.shape[0], X_0.shape[1])\n",
        "\n",
        "# build network topology\n",
        "model = keras.Sequential()\n",
        "\n",
        "# 2 LSTM layers\n",
        "model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n",
        "model.add(keras.layers.LSTM(32))\n",
        "# dense layer\n",
        "model.add(keras.layers.Dense(32, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.3))\n",
        "\n",
        "# output layer\n",
        "model.add(keras.layers.Dense(5, activation='softmax'))\n",
        "\n",
        "## show summary\n",
        "print(model.summary())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_2 (LSTM)                (None, 1292, 64)          20736     \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 32)                12416     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 32)                1056      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 5)                 165       \n",
            "=================================================================\n",
            "Total params: 34,373\n",
            "Trainable params: 34,373\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyISG9S6zBJk"
      },
      "source": [
        "optimiser = keras.optimizers.Adam(learning_rate=0.0001)\n",
        "model.compile(optimizer=optimiser,\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['acc']) #,tf.keras.metrics.Recall()]\n",
        "checkpoint = ModelCheckpoint(WEIGHTS_FILE, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XRPi9ICP4USh",
        "outputId": "e17e03d7-0f84-463f-a3a2-ebb8cb6a779d"
      },
      "source": [
        "# Y_train_2 = load_pickle(LABELS_FILE)\n",
        "# print(Y_train_2.shape)\n",
        "# print(Y_train_2[0])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(57207, 5)\n",
            "[0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IW_Lcwq248rC",
        "outputId": "dbf9f911-53f5-4265-8c1c-6b8d90cbd51c"
      },
      "source": [
        "label_32_0 = Y_train[0:32]\n",
        "label_32_0.shape"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(32, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LShanfxFzBMN"
      },
      "source": [
        "# history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=50, callbacks = callbacks_list, verbose=1) #, class_weight = dict_class_weight)"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZjhL_DZ9Fou",
        "outputId": "be7679d9-f53a-4b19-c14d-11cabe6bad7a"
      },
      "source": [
        "TOTAL_NUM_FILES = len(files)\n",
        "print(f\"TOTAL_NUM_FILES = {TOTAL_NUM_FILES}\")"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TOTAL_NUM_FILES = 35560\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvmWBi-o2wEq"
      },
      "source": [
        "## https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/#download-the-code\n",
        "# global count\n",
        "# count = 1\n",
        "def my_generator(base_folder, batch_size): # , count=1\n",
        "    count = 1\n",
        "    \n",
        "    while True:\n",
        "        if count+batch_size < TOTAL_NUM_FILES:\n",
        "            file_names = [get_name_pickle(cnt) for cnt in range(count, count+batch_size)]\n",
        "            # print(f\"Getting from 1st cond, file_names = {file_names[-1]}\")\n",
        "            objects = [load_pickle(file_name) for file_name in file_names]\n",
        "            labels = Y_train[count-1: count-1+batch_size]\n",
        "            yield (np.asarray(objects), np.asarray(labels))\n",
        "        else:\n",
        "            count = 1\n",
        "            file_names = [get_name_pickle(cnt) for cnt in range(count, count+batch_size)]\n",
        "            # print(f\">> Getting from 2nd cond, file_names = {file_names[-1]}\")\n",
        "            objects = [load_pickle(file_name) for file_name in file_names]\n",
        "            labels = Y_train[count-1: count-1+batch_size]\n",
        "            yield (np.asarray(objects), np.asarray(labels))\n",
        "\n",
        "        count += batch_size\n",
        "\n",
        "\n",
        "########################################################################################\n",
        "# x, y = my_generator(base_folder=BASE_FOLDER, batch_size=32, count=33)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpz34jGr6zkj"
      },
      "source": [
        "gen = my_generator(base_folder=BASE_FOLDER, batch_size=2) # , count=33\n",
        "x, y = gen.__next__()"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54CliZLn61E3",
        "outputId": "89bde09c-3796-4f68-e2cf-f6f0389cf1b1"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 1292, 16), (2, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qvVTm71x61HF",
        "outputId": "010bcee3-c674-4fa7-cb28-f433d966c4f1"
      },
      "source": [
        "y"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDdvmGGi61JO"
      },
      "source": [
        ""
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idDkpuin624v"
      },
      "source": [
        "## Fit gen model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vIvmakb_Bob"
      },
      "source": [
        "X_val = load_pickle(file_name = \"/content/drive/MyDrive/Audio classification/mfccs/val_16_2048_512.pkl\")\n",
        "Y_val = load_pickle(file_name = \"/content/drive/MyDrive/Audio classification/labels/val_16_2048_512.pkl\")"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1awQfFe-7Ak",
        "outputId": "da9564b2-a2c2-497a-c78f-40416a8f167c"
      },
      "source": [
        "print(f\"NUM_TRAIN_FILES = {NUM_TRAIN_FILES}\")\n",
        "# print(f\"X_val.shape = {X_val.shape}, Y_val.shape = {Y_val.shape}\")\n",
        "Y_val = tf.keras.utils.to_categorical(Y_val)\n",
        "print(X_val[0].shape, Y_val[0])"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NUM_TRAIN_FILES = 35560\n",
            "(1292, 16) [1. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i513fJptzBOc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e20be91-2e0c-496c-bbc8-55b37856e6e9"
      },
      "source": [
        "BS = 32 # batch_size = BS = 32\n",
        "NUM_EPOCHS = 2\n",
        "\n",
        "\n",
        "history_gen = model.fit(\n",
        "    x = my_generator(base_folder=BASE_FOLDER, batch_size=BS),\n",
        "    steps_per_epoch = NUM_TRAIN_FILES // BS,\n",
        "    validation_data = (X_val, Y_val),\n",
        "    validation_steps = NUM_TRAIN_FILES // BS,\n",
        "    epochs = NUM_EPOCHS\n",
        ")\n",
        "\n",
        "\n",
        "# H = model.fit(\n",
        "# \tx=trainGen,\n",
        "# \tsteps_per_epoch=NUM_TRAIN_FILES // BS,\n",
        "# \tvalidation_data=testGen,\n",
        "# \tvalidation_steps=NUM_TEST_IMAGES // BS,\n",
        "# \tepochs=NUM_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "   2/1111 [..............................] - ETA: 25:32 - loss: 1.5945 - acc: 0.1875"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILcB3GMC1YPb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ri4f-SYh1YSC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxa9NlPT1YU9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpmN0tAV1YXi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LUx4Kys1YaK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK2dQn5szBQf"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}